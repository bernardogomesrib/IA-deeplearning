{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.3\n",
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "print(tf.__version__)\n",
    "print(keras_preprocessing.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "tf.Tensor(\n",
      "[[1. 3.]\n",
      " [3. 7.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Verificar se a GPU está disponível\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "# Criar um tensor simples\n",
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "    b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1821, 4)\n",
      "(1456, 4)\n",
      "(365, 4)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "tf.config.run_functions_eagerly(True)\n",
    "df = pd.read_csv(\"train.csv\", index_col=0)\n",
    "print(df.shape)\n",
    "df.head()\n",
    "\n",
    "\n",
    "train_set, valid_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(train_set.shape)\n",
    "print(valid_set.shape)\n",
    "SOURCE = 'images/train'\n",
    "VALID_DIR = 'temp/valid/'\n",
    "TRAIN_DIR = 'temp/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Mudar o diretório de trabalho\n",
    "os.chdir('e:/gitHub2/IA-deeplearning/plant-pathology')\n",
    "\n",
    "# Deletar o diretório temporário, se existir\n",
    "if os.path.exists('temp'):\n",
    "    shutil.rmtree('temp')\n",
    "\n",
    "# Criar o diretório temporário\n",
    "os.mkdir('temp')\n",
    "\n",
    "# Criar subdiretórios para treinamento\n",
    "os.mkdir('temp/train')\n",
    "os.mkdir('temp/train/healthy')\n",
    "os.mkdir('temp/train/multiple_diseases')\n",
    "os.mkdir('temp/train/rust')\n",
    "os.mkdir('temp/train/scab')\n",
    "\n",
    "# Criar subdiretórios para validação\n",
    "os.mkdir('temp/valid')\n",
    "os.mkdir('temp/valid/healthy')\n",
    "os.mkdir('temp/valid/multiple_diseases')\n",
    "os.mkdir('temp/valid/rust')\n",
    "os.mkdir('temp/valid/scab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthy 100\n",
      "multiple_diseases 18\n",
      "rust 120\n",
      "scab 127\n",
      "healthy 416\n",
      "multiple_diseases 73\n",
      "rust 502\n",
      "scab 465\n"
     ]
    }
   ],
   "source": [
    "# copy images to train directory\n",
    "from shutil import copyfile\n",
    "\n",
    "# copy images to valid directory\n",
    "for index, data in valid_set.iterrows():\n",
    "    label = df.columns[np.argmax(data)]\n",
    "    filepath = os.path.join(SOURCE, index + \".jpg\")\n",
    "    destination = os.path.join(VALID_DIR, label, index + \".jpg\")\n",
    "    copyfile(filepath, destination)\n",
    "    \n",
    "for subdir in os.listdir(VALID_DIR):\n",
    "    print(subdir, len(os.listdir(os.path.join(VALID_DIR, subdir))))\n",
    "\n",
    "\n",
    "# copy images to train directory\n",
    "for index, data in train_set.iterrows():\n",
    "    label = df.columns[np.argmax(data)]\n",
    "    filepath = os.path.join(SOURCE, index + \".jpg\")\n",
    "    destination = os.path.join(TRAIN_DIR, label, index + \".jpg\")\n",
    "    copyfile(filepath, destination)\n",
    "    \n",
    "for subdir in os.listdir(TRAIN_DIR):\n",
    "    print(subdir, len(os.listdir(os.path.join(TRAIN_DIR, subdir))))\n",
    "\n",
    "healthy_dir = os.path.join(TRAIN_DIR, 'healthy')\n",
    "mdiseases_dir = os.path.join(TRAIN_DIR, 'multiple_diseases')\n",
    "scab_dir = os.path.join(TRAIN_DIR, 'scab')\n",
    "rust_dir = os.path.join(TRAIN_DIR, 'rust')\n",
    "\n",
    "healthy_files = os.listdir(healthy_dir)\n",
    "mdiseases_files = os.listdir(mdiseases_dir)\n",
    "scab_files = os.listdir(scab_dir)\n",
    "rust_files = os.listdir(rust_dir) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1456 images belonging to 4 classes.\n",
      "Found 365 images belonging to 4 classes.\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_65 (Conv2D)          (None, 223, 148, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d_58 (MaxPoolin  (None, 111, 74, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 109, 72, 64)       36928     \n",
      "                                                                 \n",
      " max_pooling2d_59 (MaxPoolin  (None, 54, 36, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 52, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_60 (MaxPoolin  (None, 26, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 24, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_61 (MaxPoolin  (None, 12, 7, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 10, 5, 256)        295168    \n",
      "                                                                 \n",
      " flatten_13 (Flatten)        (None, 12800)             0         \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 12800)             0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 512)               6554112   \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,111,492\n",
      "Trainable params: 7,111,492\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nmodel = tf.keras.models.Sequential([\\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(170, 150, 3)),\\n    tf.keras.layers.MaxPooling2D(2, 2),\\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Conv2D(256, (3,3), activation='sigmoid'),\\n    tf.keras.layers.MaxPooling2D(2,2),\\n    tf.keras.layers.Conv2D(256, (3,3), activation='tanh'),\\n    tf.keras.layers.Flatten(),\\n    tf.keras.layers.Dropout(0.5),\\n    tf.keras.layers.Dense(512, activation='relu'),\\n    tf.keras.layers.Dense(4, activation='softmax')\\n])\\n\\nmodel.summary()\\n\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "SOURCE = 'images/train'\n",
    "VALID_DIR = 'temp/valid/'\n",
    "TRAIN_DIR = 'temp/train/'\n",
    "\n",
    "training_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                      width_shift_range=0.2,\n",
    "                                      height_shift_range=0.2,\n",
    "                                      shear_range=0.2,\n",
    "                                      zoom_range=0.2,\n",
    "                                      horizontal_flip=True)\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(TRAIN_DIR, target_size=(225, 150), class_mode='categorical')\n",
    "validation_generator = validation_datagen.flow_from_directory(VALID_DIR, target_size=(225, 150), class_mode='categorical')\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(225, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='tanh'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(170, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='sigmoid'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(256, (3,3), activation='tanh'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "temp/train/ temp/valid/\n",
      "Epoch 1/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1978 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.1978 - accuracy: 0.3438\n",
      "Epoch 2/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.9398 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.9398 - accuracy: 0.1875\n",
      "Epoch 3/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2793 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2793 - accuracy: 0.2812\n",
      "Epoch 4/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3228 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3228 - accuracy: 0.2500\n",
      "Epoch 5/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2277 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2277 - accuracy: 0.2812\n",
      "Epoch 6/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3279 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3279 - accuracy: 0.2188\n",
      "Epoch 7/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1825 - accuracy: 0.4375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1825 - accuracy: 0.4375\n",
      "Epoch 8/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0943 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0943 - accuracy: 0.4688\n",
      "Epoch 9/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1258 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1258 - accuracy: 0.3438\n",
      "Epoch 10/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3629 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3629 - accuracy: 0.2500\n",
      "Epoch 11/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1566 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1566 - accuracy: 0.4688\n",
      "Epoch 12/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2474 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2474 - accuracy: 0.3438\n",
      "Epoch 13/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0905 - accuracy: 0.5625WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 1.0905 - accuracy: 0.5625\n",
      "Epoch 14/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3040 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3040 - accuracy: 0.4062\n",
      "Epoch 15/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.2527 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2.2527 - accuracy: 0.3438\n",
      "Epoch 16/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3153 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3153 - accuracy: 0.3750\n",
      "Epoch 17/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2365 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2365 - accuracy: 0.3750\n",
      "Epoch 18/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2053 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2053 - accuracy: 0.2500\n",
      "Epoch 19/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1932 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1932 - accuracy: 0.3750\n",
      "Epoch 20/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.5283 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.5283 - accuracy: 0.1875\n",
      "Epoch 21/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3054 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3054 - accuracy: 0.2500\n",
      "Epoch 22/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2567 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2567 - accuracy: 0.3438\n",
      "Epoch 23/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2018 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2018 - accuracy: 0.3438\n",
      "Epoch 24/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2225 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2225 - accuracy: 0.4062\n",
      "Epoch 25/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2975 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2975 - accuracy: 0.3750\n",
      "Epoch 26/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3360 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3360 - accuracy: 0.2500\n",
      "Epoch 27/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2191 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2191 - accuracy: 0.4062\n",
      "Epoch 28/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3484 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3484 - accuracy: 0.2188\n",
      "Epoch 29/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2955 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2955 - accuracy: 0.2812\n",
      "Epoch 30/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2591 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2591 - accuracy: 0.3750\n",
      "Epoch 31/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2039 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2039 - accuracy: 0.3750\n",
      "Epoch 32/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3011 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3011 - accuracy: 0.3750\n",
      "Epoch 33/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2521 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2521 - accuracy: 0.4688\n",
      "Epoch 34/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2199 - accuracy: 0.3125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2199 - accuracy: 0.3125\n",
      "Epoch 35/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1963 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1963 - accuracy: 0.3438\n",
      "Epoch 36/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2497 - accuracy: 0.5000WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2497 - accuracy: 0.5000\n",
      "Epoch 37/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2193 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2193 - accuracy: 0.4062\n",
      "Epoch 38/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2434 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2434 - accuracy: 0.2188\n",
      "Epoch 39/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1447 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1447 - accuracy: 0.3438\n",
      "Epoch 40/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2155 - accuracy: 0.4375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2155 - accuracy: 0.4375\n",
      "Epoch 41/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4558 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4558 - accuracy: 0.1875\n",
      "Epoch 42/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1137 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1137 - accuracy: 0.4062\n",
      "Epoch 43/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1546 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1546 - accuracy: 0.2500\n",
      "Epoch 44/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3240 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3240 - accuracy: 0.3438\n",
      "Epoch 45/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1811 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1811 - accuracy: 0.4062\n",
      "Epoch 46/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3528 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3528 - accuracy: 0.2812\n",
      "Epoch 47/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.6045 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.6045 - accuracy: 0.2188\n",
      "Epoch 48/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2405 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2405 - accuracy: 0.3750\n",
      "Epoch 49/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3705 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3705 - accuracy: 0.4062\n",
      "Epoch 50/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2421 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2421 - accuracy: 0.4688\n",
      "Epoch 51/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3383 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3383 - accuracy: 0.2812\n",
      "Epoch 52/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3181 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3181 - accuracy: 0.2500\n",
      "Epoch 53/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3251 - accuracy: 0.2188WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3251 - accuracy: 0.2188\n",
      "Epoch 54/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2038 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2038 - accuracy: 0.2812\n",
      "Epoch 55/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4928 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4928 - accuracy: 0.1875\n",
      "Epoch 56/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2133 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2133 - accuracy: 0.3750\n",
      "Epoch 57/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1983 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1983 - accuracy: 0.3438\n",
      "Epoch 58/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2629 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2629 - accuracy: 0.3438\n",
      "Epoch 59/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2062 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2062 - accuracy: 0.3438\n",
      "Epoch 60/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2489 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2489 - accuracy: 0.4688\n",
      "Epoch 61/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2021 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2021 - accuracy: 0.3750\n",
      "Epoch 62/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1418 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1418 - accuracy: 0.4688\n",
      "Epoch 63/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1206 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1206 - accuracy: 0.3750\n",
      "Epoch 64/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7866 - accuracy: 0.3125WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.7866 - accuracy: 0.3125\n",
      "Epoch 65/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4988 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4988 - accuracy: 0.1875\n",
      "Epoch 66/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1928 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1928 - accuracy: 0.3438\n",
      "Epoch 67/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4911 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4911 - accuracy: 0.4062\n",
      "Epoch 68/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2361 - accuracy: 0.4375WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2361 - accuracy: 0.4375\n",
      "Epoch 69/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2197 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2197 - accuracy: 0.2812\n",
      "Epoch 70/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2132 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2132 - accuracy: 0.4062\n",
      "Epoch 71/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4346 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4346 - accuracy: 0.1562\n",
      "Epoch 72/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3107 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3107 - accuracy: 0.3438\n",
      "Epoch 73/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2277 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2277 - accuracy: 0.3438\n",
      "Epoch 74/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3311 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3311 - accuracy: 0.1875\n",
      "Epoch 75/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2933 - accuracy: 0.1875WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2933 - accuracy: 0.1875\n",
      "Epoch 76/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1949 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1949 - accuracy: 0.2500\n",
      "Epoch 77/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2779 - accuracy: 0.2812WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2779 - accuracy: 0.2812\n",
      "Epoch 78/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2511 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2511 - accuracy: 0.4062\n",
      "Epoch 79/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.4034 - accuracy: 0.2500WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.4034 - accuracy: 0.2500\n",
      "Epoch 80/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2971 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2971 - accuracy: 0.3438\n",
      "Epoch 81/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2302 - accuracy: 0.3438WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2302 - accuracy: 0.3438\n",
      "Epoch 82/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.3782 - accuracy: 0.1562WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.3782 - accuracy: 0.1562\n",
      "Epoch 83/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2197 - accuracy: 0.4688WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2197 - accuracy: 0.4688\n",
      "Epoch 84/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.2487 - accuracy: 0.3750WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.2487 - accuracy: 0.3750\n",
      "Epoch 85/250\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1969 - accuracy: 0.4062WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.1969 - accuracy: 0.4062\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m validation_generator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_generator) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(validation_generator) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 23\u001b[0m         history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcheckpoint_loss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: The generators do not have any data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\berna\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\berna\\anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py:1397\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1395\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch, iterator \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39menumerate_epochs():\n\u001b[1;32m-> 1397\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_metrics\u001b[49m()\n\u001b[0;32m   1398\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1399\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Compilar o modelo\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'], run_eagerly=True)\n",
    "\n",
    "# Callbacks\n",
    "#early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=5)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"cnngpu.keras\", save_best_only=True)\n",
    "checkpoint_loss = tf.keras.callbacks.ModelCheckpoint(filepath='best_model_loss.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "checkpoint_accuracy = tf.keras.callbacks.ModelCheckpoint(filepath='best_model_accuracy.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
    "\n",
    "\n",
    "\n",
    "# Calcular steps_per_epoch e validation_steps\n",
    "batch_size = 32\n",
    "steps_per_epoch = len(train_generator) // batch_size\n",
    "validation_steps = len(validation_generator) // batch_size\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(TRAIN_DIR, VALID_DIR)\n",
    "# Verificar se os generators têm pelo menos um lote de dados\n",
    "if train_generator is not None and validation_generator is not None:\n",
    "    if len(train_generator) > 0 and len(validation_generator) > 0:\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=250,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_steps,\n",
    "            callbacks=[checkpoint_cb,checkpoint_accuracy,checkpoint_loss],\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: The generators do not have any data.\")\n",
    "else:\n",
    "    print(\"Error: One of the generators is None.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "#val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "#val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, loss, 'b', label='loss')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Testar diferentes batch sizes\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m [ \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m1024\u001b[39m]:\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mtest_batch_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36mtest_batch_size\u001b[1;34m(batch_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_batch_size\u001b[39m(batch_size):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 6\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m funciona!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m tf\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mResourceExhaustedError:\n",
      "File \u001b[1;32mc:\\Users\\berna\\anaconda3\\envs\\tfg\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\berna\\anaconda3\\envs\\tfg\\lib\\site-packages\\keras_preprocessing\\image\\utils.py:111\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[0;32m    109\u001b[0m     color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    112\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    114\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "\n",
    "# Função para testar diferentes batch sizes\n",
    "\n",
    "def test_batch_size(batch_size):\n",
    "  \n",
    "    try:\n",
    "        model.fit(\n",
    "            train_generator,\n",
    "            epochs=1,\n",
    "            steps_per_epoch=len(train_generator) // batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=len(validation_generator) // batch_size,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "        print(f\"Batch size {batch_size} funciona!\")\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        print(f\"Batch size {batch_size} é muito grande para a memória da GPU.\")\n",
    "\n",
    "# Testar diferentes batch sizes\n",
    "for batch_size in [ 256, 512, 1024]:\n",
    "    test_batch_size(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(PIL\u001b[38;5;241m.\u001b[39m__version__)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "print(PIL.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at C:\\Users\\berna\\anaconda3\\envs\\tf2:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "absl-py                   2.1.0                    pypi_0    pypi\n",
      "asttokens                 2.4.1                    pypi_0    pypi\n",
      "astunparse                1.6.3                    pypi_0    pypi\n",
      "blas                      1.0                         mkl  \n",
      "bottleneck                1.3.7            py39h9128911_0  \n",
      "ca-certificates           2024.7.4             h56e8100_0    conda-forge\n",
      "cachetools                5.5.0                    pypi_0    pypi\n",
      "certifi                   2024.7.4                 pypi_0    pypi\n",
      "charset-normalizer        3.3.2                    pypi_0    pypi\n",
      "colorama                  0.4.6                    pypi_0    pypi\n",
      "comm                      0.2.2                    pypi_0    pypi\n",
      "cudatoolkit               11.2.2              h7d7167e_13    conda-forge\n",
      "cudnn                     8.1.0.77             h3e0f4f4_0    conda-forge\n",
      "debugpy                   1.8.5                    pypi_0    pypi\n",
      "decorator                 5.1.1                    pypi_0    pypi\n",
      "exceptiongroup            1.2.2                    pypi_0    pypi\n",
      "executing                 2.0.1                    pypi_0    pypi\n",
      "flatbuffers               1.12                     pypi_0    pypi\n",
      "gast                      0.4.0                    pypi_0    pypi\n",
      "google-auth               2.34.0                   pypi_0    pypi\n",
      "google-auth-oauthlib      0.4.6                    pypi_0    pypi\n",
      "google-pasta              0.2.0                    pypi_0    pypi\n",
      "grpcio                    1.66.0                   pypi_0    pypi\n",
      "h5py                      3.11.0                   pypi_0    pypi\n",
      "icc_rt                    2022.1.0             h6049295_2  \n",
      "idna                      3.8                      pypi_0    pypi\n",
      "importlib-metadata        8.4.0                    pypi_0    pypi\n",
      "intel-openmp              2023.1.0         h59b6b97_46320  \n",
      "ipykernel                 6.29.5                   pypi_0    pypi\n",
      "ipython                   8.18.1                   pypi_0    pypi\n",
      "jedi                      0.19.1                   pypi_0    pypi\n",
      "joblib                    1.4.2            py39haa95532_0  \n",
      "jupyter-client            8.6.2                    pypi_0    pypi\n",
      "jupyter-core              5.7.2                    pypi_0    pypi\n",
      "keras                     3.5.0                    pypi_0    pypi\n",
      "keras-nightly             3.4.1.dev2024080903          pypi_0    pypi\n",
      "keras-preprocessing       1.1.2                    pypi_0    pypi\n",
      "libclang                  18.1.1                   pypi_0    pypi\n",
      "llvmlite                  0.43.0                   pypi_0    pypi\n",
      "markdown                  3.7                      pypi_0    pypi\n",
      "markdown-it-py            3.0.0                    pypi_0    pypi\n",
      "markupsafe                2.1.5                    pypi_0    pypi\n",
      "matplotlib-inline         0.1.7                    pypi_0    pypi\n",
      "mdurl                     0.1.2                    pypi_0    pypi\n",
      "mkl                       2023.1.0         h6b88ed4_46358  \n",
      "mkl-service               2.4.0            py39h2bbff1b_1  \n",
      "mkl_fft                   1.3.8            py39h2bbff1b_0  \n",
      "mkl_random                1.2.4            py39h59b6b97_0  \n",
      "ml-dtypes                 0.3.2                    pypi_0    pypi\n",
      "namex                     0.0.8                    pypi_0    pypi\n",
      "nest-asyncio              1.6.0                    pypi_0    pypi\n",
      "numba                     0.60.0                   pypi_0    pypi\n",
      "numexpr                   2.8.7            py39h2cd9be0_0  \n",
      "numpy                     1.26.3                   pypi_0    pypi\n",
      "oauthlib                  3.2.2                    pypi_0    pypi\n",
      "openssl                   3.3.1                h2466b09_3    conda-forge\n",
      "opt-einsum                3.3.0                    pypi_0    pypi\n",
      "optree                    0.12.1                   pypi_0    pypi\n",
      "packaging                 24.1                     pypi_0    pypi\n",
      "pandas                    2.2.2                    pypi_0    pypi\n",
      "parso                     0.8.4                    pypi_0    pypi\n",
      "pip                       24.2             py39haa95532_0  \n",
      "platformdirs              4.2.2                    pypi_0    pypi\n",
      "prompt-toolkit            3.0.47                   pypi_0    pypi\n",
      "protobuf                  4.25.4                   pypi_0    pypi\n",
      "psutil                    6.0.0                    pypi_0    pypi\n",
      "pure-eval                 0.2.3                    pypi_0    pypi\n",
      "pyasn1                    0.6.0                    pypi_0    pypi\n",
      "pyasn1-modules            0.4.0                    pypi_0    pypi\n",
      "pybind11-abi              5                    hd3eb1b0_0  \n",
      "pygments                  2.18.0                   pypi_0    pypi\n",
      "python                    3.9.19               h1aa4202_1  \n",
      "python-dateutil           2.9.0post0       py39haa95532_2  \n",
      "python-tzdata             2023.3             pyhd3eb1b0_0  \n",
      "pytz                      2024.1           py39haa95532_0  \n",
      "pywin32                   306                      pypi_0    pypi\n",
      "pyzmq                     26.2.0                   pypi_0    pypi\n",
      "requests                  2.32.3                   pypi_0    pypi\n",
      "requests-oauthlib         2.0.0                    pypi_0    pypi\n",
      "rich                      13.8.0                   pypi_0    pypi\n",
      "rsa                       4.9                      pypi_0    pypi\n",
      "scikit-learn              1.5.1                    pypi_0    pypi\n",
      "scipy                     1.13.1           py39h8640f81_0  \n",
      "setuptools                72.1.0           py39haa95532_0  \n",
      "six                       1.15.0                   pypi_0    pypi\n",
      "sqlite                    3.45.3               h2bbff1b_0  \n",
      "stack-data                0.6.3                    pypi_0    pypi\n",
      "tbb                       2021.8.0             h59b6b97_0  \n",
      "tensorboard               2.9.1                    pypi_0    pypi\n",
      "tensorboard-data-server   0.7.2                    pypi_0    pypi\n",
      "tensorboard-plugin-wit    1.8.1                    pypi_0    pypi\n",
      "tensorflow                2.9.3                    pypi_0    pypi\n",
      "tensorflow-estimator      2.9.0                    pypi_0    pypi\n",
      "tensorflow-io-gcs-filesystem 0.31.0                   pypi_0    pypi\n",
      "termcolor                 1.1.0                    pypi_0    pypi\n",
      "threadpoolctl             3.5.0            py39h9909e9c_0  \n",
      "tornado                   6.4.1                    pypi_0    pypi\n",
      "traitlets                 5.14.3                   pypi_0    pypi\n",
      "typing-extensions         4.12.2                   pypi_0    pypi\n",
      "tzdata                    2024a                h04d1e81_0  \n",
      "ucrt                      10.0.22621.0         h57928b3_0    conda-forge\n",
      "urllib3                   2.2.2                    pypi_0    pypi\n",
      "vc                        14.40                h2eaa2aa_0  \n",
      "vc14_runtime              14.40.33810         hcc2c482_20    conda-forge\n",
      "vs2015_runtime            14.40.33810         h3bf8584_20    conda-forge\n",
      "wcwidth                   0.2.13                   pypi_0    pypi\n",
      "werkzeug                  3.0.4                    pypi_0    pypi\n",
      "wheel                     0.43.0           py39haa95532_0  \n",
      "wrapt                     1.12.1                   pypi_0    pypi\n",
      "zipp                      3.20.1                   pypi_0    pypi\n"
     ]
    }
   ],
   "source": [
    "! conda list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
